{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuklcMHO6xph"
      },
      "outputs": [],
      "source": [
        "!pip install azure-storage-blob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HStoRtOp633i"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "import glob\n",
        "import json\n",
        "import csv\n",
        "import time\n",
        "import zipfile\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from  azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
        "from google.colab import userdata\n",
        "from google.colab import files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lFc1w3G6_JA"
      },
      "outputs": [],
      "source": [
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.DEBUG)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNkQWSHj6--6"
      },
      "outputs": [],
      "source": [
        "def download_test_data(blob_names=[]):\n",
        "  # Replace with your Azure Storage connection string\n",
        "  connection_string = userdata.get(\"YOUR_AZURE_STORAGE_CONNECTION_STRING\")\n",
        "\n",
        "  # Replace with the name of your container and the blob name you want to download\n",
        "  container_name = userdata.get(\"YOUR_CONTAINER_NAME\")\n",
        "  blob_names = [\"appspecificdata.csv\"]\n",
        "\n",
        "  # Create a BlobServiceClient object from the connection string\n",
        "  blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
        "\n",
        "  for blob_name in blob_names:\n",
        "    # Get a reference to the target blob\n",
        "    blob_client = blob_service_client.get_blob_client(container_name, blob_name)\n",
        "    # Download the blob content to a file\n",
        "    with open(blob_name, 'wb') as downloaded_file:\n",
        "      downloaded_file.write(blob_client.download_blob().readall())\n",
        "    print('File downloaded successfully!')\n",
        "\n",
        "\n",
        "# Assuming you have a DataFrame named 'df'\n",
        "def create_text_file(row, typeofrow):\n",
        "    row_data = ''.join(row.astype(str))\n",
        "    file_path = f\"/content/{typeofrow}/file_{row.name}.txt\"\n",
        "\n",
        "    # Create the directory if it doesn't exist\n",
        "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "\n",
        "    # Write the row data to the text file\n",
        "    with open(file_path, 'w', encoding='utf-8') as f:\n",
        "      print(file_path)\n",
        "      f.write(row_data)\n",
        "\n",
        "def zip_and_download(typeoffile):\n",
        "  # Zip the folders\n",
        "  with zipfile.ZipFile(f'{typeoffile}.zip', 'w') as zip_obj:\n",
        "    for folder_name, subfolders, filess in os.walk(f\"/content/{typeoffile}/\"):\n",
        "        for file in filess:\n",
        "            file_path = os.path.join(folder_name, file)\n",
        "            zip_obj.write(file_path)\n",
        "  # Download the zipped folders\n",
        "  files.download(f'{typeoffile}.zip')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# def convert_large_csv_to_small_csv(inputcsvfile, outputcsvfile, percent):\n",
        "#   large_df = pd.read_csv(inputcsvfile)\n",
        "#   small_df = large_df.sample(frac=percent)  # 1% of the rows\n",
        "#   small_df.to_csv(outputcsvfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XabkJZJ38MAX"
      },
      "outputs": [],
      "source": [
        "#To dowload the test data\n",
        "download_test_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnC9BNlK5p4j"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"appspecificdata.csv\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4syjG8l-9Joo"
      },
      "outputs": [],
      "source": [
        "df.shape\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6g82rHqG9TEO"
      },
      "outputs": [],
      "source": [
        "df_notna = df[df[\"errorCode\"].notna()]\n",
        "df_notna.head()\n",
        "df_notna.shape\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWIR3IB2hcV7"
      },
      "outputs": [],
      "source": [
        "df_isna = df[df[\"errorCode\"].isna()]\n",
        "df_isna.head()\n",
        "df_isna.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOno9p4a9aFC"
      },
      "outputs": [],
      "source": [
        "sum = df_isna.shape[0]+df_notna.shape[0]\n",
        "percentoferror = df_notna.shape[0] * 100 /sum\n",
        "print(percentoferror)\n",
        "percentofnoerror = df_isna.shape[0] * 100/sum\n",
        "print(percentofnoerror)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyUu75_ljR4H"
      },
      "outputs": [],
      "source": [
        "#df_isna.apply(lambda row, arg1: create_text_file(row, arg1), args=(\"noerror\"), axis=1)\n",
        "\n",
        "df_isna.apply(create_text_file, args=('noerror',), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oP0Jj8RpoMFA"
      },
      "outputs": [],
      "source": [
        "df_notna.apply(create_text_file, args=('error',), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "zip_and_download(\"error\")\n",
        "zip_and_download(\"noerror\")"
      ],
      "metadata": {
        "id": "VIHyDCIbb_AR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4paHGbmnppzTmQCFaiFzD"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}